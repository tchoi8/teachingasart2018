*Overview*

As more and more primary and secondary source material appears on websites, it is becoming increasingly important for scholars and librarians to learn how to collect with material at scale. Participants in this workshop will learn how to create a textual corpus using web scraping techniques. By the end of the workshop, participants will be comfortable using a variety of web scraping techniques, and will be able to generate a corpus and to prepare it for further analysis.

*Learning Objectives*

Participants will develop an understanding of how websites can be viewed as source material for research projects, and develop skills to scrape content from websites.

*Learning Outcomes*

Participants will learn:
- Why web scraping can be beneficial to their research
- The basic concepts of web scraping
- Technical skills to scrape content in a variety of contexts
- A more sophisticated approach to thinking of websites as potential data sources and how to collect such data


**Workshop Notes**

*Introductions*
Who are you? Who am I? How much experience does everyone have with programming?

*Caveats*
I'm not an expert; this is not a proper library "service"; copyright and intellectual property issues with scraping

*Why Web Scraping?*
To collect data for research project; especially in humanities in social sciences; generate corpora for text analysis projects

*Structure of Web Pages*
Show HTML/CSS of a page (view source); there's an underlying structure that allows us to extract data; each page has a slightly different structure; dynamically generated pages are difficult; only captures text, not images/video/audio

*Hands-on Demos*
Basic example: using Jupyter Notebooks, write a basic program together that will extract the link text from a Craigslist page
Intermediate example: write a program together that will extract the headline (link text) and the article link from a search for Michael Brown on the St. Louis Post Dispatch; explain how you can use the output from this program to visit each of those links and collect that text of the actual articles
Advanced example: write a program together that collects reviews from an Yahoo Answers, and uses pagination to gather the multiple pages of results

Materials are available at https://github.com/coblezc/teachingasart-webscraping-workshop

***

Unfortunately, no one showed up for the workshop :( I created [an event](https://nyu.libcal.com/event/4135322) on the library's event calendar four days before the event. The calendar is publicly viewable, and there was one student from Stern who registered, but they did not show up. I also emailed everyone in the Teaching as Art class to invite them to the workshop. Although the workshop did not take place, I was prepared to teach and actually felt that this was a helpful experience. You never know if people will show up or not, so you have to be prepared. It was also helpful to reflect on how I might do the workshop differently next time. Perhaps Friday afternoon is not the best time to offer a workshop. And, was the classroom empty because I didn't reach people where they were at, or was it because that afternoon was the first nice day of the year and who wants to spend a Friday afternoon in a workshop? Were there things I could have improved or, even if I had, the room would still be empty?
